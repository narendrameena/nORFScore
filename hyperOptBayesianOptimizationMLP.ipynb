{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "###-----------------------------------------------------##\n",
    "#@author narumeena \n",
    "#@description Multilayer Preceptron \n",
    "#                -- with bayesian optimization\n",
    "#                -- with drop out node \n",
    "###----------------------------------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "from sklearn.model_selection import train_test_split # split the dataset into traninig and testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138665, 56)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data from filterd dataset with maximum 30% files \n",
    "filtredAttributes = pd.read_csv(\"../analysis/trainingDataSet/case_control_filtred.csv\", sep=\",\")\n",
    "filtredAttributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ref</th>\n",
       "      <th>Alt</th>\n",
       "      <th>Consequence</th>\n",
       "      <th>GC</th>\n",
       "      <th>CpG</th>\n",
       "      <th>minDistTSS</th>\n",
       "      <th>minDistTSE</th>\n",
       "      <th>priPhCons</th>\n",
       "      <th>mamPhCons</th>\n",
       "      <th>verPhCons</th>\n",
       "      <th>...</th>\n",
       "      <th>EncodeH3K27ac-max</th>\n",
       "      <th>EncodeH3K27me3-max</th>\n",
       "      <th>EncodeH3K36me3-max</th>\n",
       "      <th>EncodeH3K79me2-max</th>\n",
       "      <th>EncodeH4K20me1-max</th>\n",
       "      <th>EncodeH2AFZ-max</th>\n",
       "      <th>EncodeDNase-max</th>\n",
       "      <th>EncodetotalRNA-max</th>\n",
       "      <th>RemapOverlapTF</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>STOP_GAINED</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.253</td>\n",
       "      <td>6715</td>\n",
       "      <td>185</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.68</td>\n",
       "      <td>9.77</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.35</td>\n",
       "      <td>9.02</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>REGULATORY</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.253</td>\n",
       "      <td>6715</td>\n",
       "      <td>185</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.71</td>\n",
       "      <td>4.85</td>\n",
       "      <td>5.68</td>\n",
       "      <td>9.77</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.35</td>\n",
       "      <td>9.02</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>NON_SYNONYMOUS</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.120</td>\n",
       "      <td>212</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>4.78</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>UPSTREAM</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.120</td>\n",
       "      <td>212</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.15</td>\n",
       "      <td>4.78</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.37</td>\n",
       "      <td>4.20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>NON_SYNONYMOUS</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.213</td>\n",
       "      <td>814</td>\n",
       "      <td>1969</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.20</td>\n",
       "      <td>5.65</td>\n",
       "      <td>28.99</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.89</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ref Alt     Consequence     GC    CpG  minDistTSS  minDistTSE  priPhCons  \\\n",
       "0   C   T     STOP_GAINED  0.715  0.253        6715         185      0.011   \n",
       "1   C   T      REGULATORY  0.715  0.253        6715         185      0.011   \n",
       "2   G   A  NON_SYNONYMOUS  0.609  0.120         212        2176      0.039   \n",
       "3   G   A        UPSTREAM  0.609  0.120         212        2176      0.039   \n",
       "4   A   C  NON_SYNONYMOUS  0.675  0.213         814        1969      0.192   \n",
       "\n",
       "   mamPhCons  verPhCons  ...  EncodeH3K27ac-max  EncodeH3K27me3-max  \\\n",
       "0      0.001        0.0  ...               0.82                1.71   \n",
       "1      0.001        0.0  ...               0.82                1.71   \n",
       "2      0.984        1.0  ...               0.92                2.15   \n",
       "3      0.984        1.0  ...               0.92                2.15   \n",
       "4      0.999        1.0  ...               2.89                1.20   \n",
       "\n",
       "   EncodeH3K36me3-max  EncodeH3K79me2-max  EncodeH4K20me1-max  \\\n",
       "0                4.85                5.68                9.77   \n",
       "1                4.85                5.68                9.77   \n",
       "2                4.78                2.63                1.94   \n",
       "3                4.78                2.63                1.94   \n",
       "4                5.65               28.99                2.07   \n",
       "\n",
       "   EncodeH2AFZ-max  EncodeDNase-max  EncodetotalRNA-max  RemapOverlapTF  \\\n",
       "0             3.58             0.35                9.02            21.0   \n",
       "1             3.58             0.35                9.02            21.0   \n",
       "2             0.87             0.37                4.20             9.0   \n",
       "3             0.87             0.37                4.20             9.0   \n",
       "4             3.21             0.34                2.89            39.0   \n",
       "\n",
       "   category  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtredAttributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ref                       0\n",
       "Alt                       0\n",
       "Consequence               0\n",
       "GC                        0\n",
       "CpG                       0\n",
       "minDistTSS                0\n",
       "minDistTSE                0\n",
       "priPhCons               143\n",
       "mamPhCons               143\n",
       "verPhCons               143\n",
       "priPhyloP               143\n",
       "mamPhyloP               143\n",
       "verPhyloP               143\n",
       "bStatistic             1058\n",
       "cHmm_E1                   0\n",
       "cHmm_E2                   0\n",
       "cHmm_E3                   0\n",
       "cHmm_E4                   0\n",
       "cHmm_E5                   0\n",
       "cHmm_E6                   0\n",
       "cHmm_E7                   0\n",
       "cHmm_E8                   0\n",
       "cHmm_E9                   0\n",
       "cHmm_E10                  0\n",
       "cHmm_E11                  0\n",
       "cHmm_E12                  0\n",
       "cHmm_E13                  0\n",
       "cHmm_E14                  0\n",
       "cHmm_E15                  0\n",
       "cHmm_E16                  0\n",
       "cHmm_E17                  0\n",
       "cHmm_E18                  0\n",
       "cHmm_E19                  0\n",
       "cHmm_E20                  0\n",
       "cHmm_E21                  0\n",
       "cHmm_E22                  0\n",
       "cHmm_E23                  0\n",
       "cHmm_E24                  0\n",
       "cHmm_E25                  0\n",
       "GerpN                     0\n",
       "GerpS                     0\n",
       "EncodeH3K4me1-max       832\n",
       "EncodeH3K4me2-max      1147\n",
       "EncodeH3K4me3-max       836\n",
       "EncodeH3K9ac-max       1016\n",
       "EncodeH3K9me3-max       704\n",
       "EncodeH3K27ac-max       888\n",
       "EncodeH3K27me3-max      856\n",
       "EncodeH3K36me3-max     1201\n",
       "EncodeH3K79me2-max     1449\n",
       "EncodeH4K20me1-max      867\n",
       "EncodeH2AFZ-max        1035\n",
       "EncodeDNase-max          38\n",
       "EncodetotalRNA-max     6088\n",
       "RemapOverlapTF        31766\n",
       "category                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 4000\n",
    "filtredAttributes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values \n",
    "\n",
    "filtredAttributes['priPhCons'].fillna(0.115,inplace=True)\n",
    "filtredAttributes['mamPhCons'].fillna(0.079,inplace=True)\n",
    "filtredAttributes['verPhCons'].fillna(0.094,inplace=True)\n",
    "filtredAttributes['priPhyloP'].fillna(-0.033,inplace=True)\n",
    "filtredAttributes['mamPhyloP'].fillna(-0.038,inplace=True)\n",
    "filtredAttributes['verPhyloP'].fillna(0.017,inplace=True)\n",
    "filtredAttributes['bStatistic'].fillna(800.261,inplace=True)\n",
    "filtredAttributes['minDistTSS'].fillna(10000000,inplace=True)\n",
    "filtredAttributes['minDistTSE'].fillna(10000000,inplace=True)\n",
    "filtredAttributes['RemapOverlapTF'].fillna(0.5,inplace=True)\n",
    "filtredAttributes['EncodeH3K4me1-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K4me2-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K4me3-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K9ac-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K9me3-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K27ac-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K27me3-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K36me3-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH3K79me2-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH4K20me1-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeH2AFZ-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodetotalRNA-max'].fillna(0,inplace=True)\n",
    "filtredAttributes['EncodeDNase-max'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ref                   0\n",
       "Alt                   0\n",
       "Consequence           0\n",
       "GC                    0\n",
       "CpG                   0\n",
       "minDistTSS            0\n",
       "minDistTSE            0\n",
       "priPhCons             0\n",
       "mamPhCons             0\n",
       "verPhCons             0\n",
       "priPhyloP             0\n",
       "mamPhyloP             0\n",
       "verPhyloP             0\n",
       "bStatistic            0\n",
       "cHmm_E1               0\n",
       "cHmm_E2               0\n",
       "cHmm_E3               0\n",
       "cHmm_E4               0\n",
       "cHmm_E5               0\n",
       "cHmm_E6               0\n",
       "cHmm_E7               0\n",
       "cHmm_E8               0\n",
       "cHmm_E9               0\n",
       "cHmm_E10              0\n",
       "cHmm_E11              0\n",
       "cHmm_E12              0\n",
       "cHmm_E13              0\n",
       "cHmm_E14              0\n",
       "cHmm_E15              0\n",
       "cHmm_E16              0\n",
       "cHmm_E17              0\n",
       "cHmm_E18              0\n",
       "cHmm_E19              0\n",
       "cHmm_E20              0\n",
       "cHmm_E21              0\n",
       "cHmm_E22              0\n",
       "cHmm_E23              0\n",
       "cHmm_E24              0\n",
       "cHmm_E25              0\n",
       "GerpN                 0\n",
       "GerpS                 0\n",
       "EncodeH3K4me1-max     0\n",
       "EncodeH3K4me2-max     0\n",
       "EncodeH3K4me3-max     0\n",
       "EncodeH3K9ac-max      0\n",
       "EncodeH3K9me3-max     0\n",
       "EncodeH3K27ac-max     0\n",
       "EncodeH3K27me3-max    0\n",
       "EncodeH3K36me3-max    0\n",
       "EncodeH3K79me2-max    0\n",
       "EncodeH4K20me1-max    0\n",
       "EncodeH2AFZ-max       0\n",
       "EncodeDNase-max       0\n",
       "EncodetotalRNA-max    0\n",
       "RemapOverlapTF        0\n",
       "category              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 4000\n",
    "filtredAttributes.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "filtredAttributes = pd.get_dummies(filtredAttributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "138660    0\n",
       "138661    0\n",
       "138662    0\n",
       "138663    0\n",
       "138664    0\n",
       "Name: category, Length: 138665, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = filtredAttributes['category']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GC</th>\n",
       "      <th>CpG</th>\n",
       "      <th>minDistTSS</th>\n",
       "      <th>minDistTSE</th>\n",
       "      <th>priPhCons</th>\n",
       "      <th>mamPhCons</th>\n",
       "      <th>verPhCons</th>\n",
       "      <th>priPhyloP</th>\n",
       "      <th>mamPhyloP</th>\n",
       "      <th>verPhyloP</th>\n",
       "      <th>...</th>\n",
       "      <th>Consequence_DOWNSTREAM</th>\n",
       "      <th>Consequence_INTRONIC</th>\n",
       "      <th>Consequence_NONCODING_CHANGE</th>\n",
       "      <th>Consequence_NON_SYNONYMOUS</th>\n",
       "      <th>Consequence_REGULATORY</th>\n",
       "      <th>Consequence_SPLICE_SITE</th>\n",
       "      <th>Consequence_STOP_GAINED</th>\n",
       "      <th>Consequence_STOP_LOST</th>\n",
       "      <th>Consequence_SYNONYMOUS</th>\n",
       "      <th>Consequence_UPSTREAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.253</td>\n",
       "      <td>6715</td>\n",
       "      <td>185</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.253</td>\n",
       "      <td>6715</td>\n",
       "      <td>185</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.120</td>\n",
       "      <td>212</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595</td>\n",
       "      <td>4.158</td>\n",
       "      <td>5.651</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.120</td>\n",
       "      <td>212</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595</td>\n",
       "      <td>4.158</td>\n",
       "      <td>5.651</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.213</td>\n",
       "      <td>814</td>\n",
       "      <td>1969</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.149</td>\n",
       "      <td>0.850</td>\n",
       "      <td>3.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GC    CpG  minDistTSS  minDistTSE  priPhCons  mamPhCons  verPhCons  \\\n",
       "0  0.715  0.253        6715         185      0.011      0.001        0.0   \n",
       "1  0.715  0.253        6715         185      0.011      0.001        0.0   \n",
       "2  0.609  0.120         212        2176      0.039      0.984        1.0   \n",
       "3  0.609  0.120         212        2176      0.039      0.984        1.0   \n",
       "4  0.675  0.213         814        1969      0.192      0.999        1.0   \n",
       "\n",
       "   priPhyloP  mamPhyloP  verPhyloP  ...  Consequence_DOWNSTREAM  \\\n",
       "0     -0.646      0.096      0.126  ...                       0   \n",
       "1     -0.646      0.096      0.126  ...                       0   \n",
       "2      0.595      4.158      5.651  ...                       0   \n",
       "3      0.595      4.158      5.651  ...                       0   \n",
       "4     -1.149      0.850      3.250  ...                       0   \n",
       "\n",
       "   Consequence_INTRONIC  Consequence_NONCODING_CHANGE  \\\n",
       "0                     0                             0   \n",
       "1                     0                             0   \n",
       "2                     0                             0   \n",
       "3                     0                             0   \n",
       "4                     0                             0   \n",
       "\n",
       "   Consequence_NON_SYNONYMOUS  Consequence_REGULATORY  \\\n",
       "0                           0                       0   \n",
       "1                           0                       1   \n",
       "2                           1                       0   \n",
       "3                           0                       0   \n",
       "4                           1                       0   \n",
       "\n",
       "   Consequence_SPLICE_SITE  Consequence_STOP_GAINED  Consequence_STOP_LOST  \\\n",
       "0                        0                        1                      0   \n",
       "1                        0                        0                      0   \n",
       "2                        0                        0                      0   \n",
       "3                        0                        0                      0   \n",
       "4                        0                        0                      0   \n",
       "\n",
       "   Consequence_SYNONYMOUS  Consequence_UPSTREAM  \n",
       "0                       0                     0  \n",
       "1                       0                     0  \n",
       "2                       0                     0  \n",
       "3                       0                     1  \n",
       "4                       0                     0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= filtredAttributes.drop('category', axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size = 0.25, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103998, 74)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.reset_index().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103998, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34667, 74)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.reset_index().values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34667, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.reset_index().values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron \n",
    "\n",
    "without the activation functions, multiple linear layers are equivalent to a single layer in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = torch.FloatTensor(x_train.reset_index().values)\n",
    "y_train = torch.FloatTensor(y_train.reset_index().values)\n",
    "\n",
    "\n",
    "x_test = torch.FloatTensor(x_test.reset_index().values)\n",
    "y_test = torch.FloatTensor(y_test.reset_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8654, 0.6196, 0.3782,  ..., 0.0590, 0.1067, 0.6129],\n",
       "        [0.2766, 0.3571, 0.3200,  ..., 0.1360, 0.2792, 0.8408],\n",
       "        [0.5934, 0.3771, 0.3449,  ..., 0.3926, 0.4703, 0.9888],\n",
       "        ...,\n",
       "        [0.9309, 0.2576, 0.2282,  ..., 0.9168, 0.3010, 0.1570],\n",
       "        [0.7813, 0.3686, 0.1573,  ..., 0.6127, 0.0459, 0.2528],\n",
       "        [0.6309, 0.7803, 0.5156,  ..., 0.6976, 0.0942, 0.0934]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "x = torch.rand(size=(65536, 94), dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separation = int(x.shape[0] * 0.8)\n",
    "train = x[:separation]\n",
    "test = x[separation:]\n",
    "\n",
    "train_dataset = CustomDataset(train)\n",
    "test_dataset = CustomDataset(test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "for train_sample in train_loader:\n",
    "    print(train_sample.shape)\n",
    "for test_sample in test_loader:\n",
    "    print(test_sample.shape)\n",
    "    # torch.Size([32, 94])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            relu = self.relu(hidden)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Feedforward(74, 100)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (69334) != input nelement (34667)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-7f012019d8bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbefore_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss before training'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbefore_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2070\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (69334) != input nelement (34667)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "before_train = criterion(y_pred.squeeze(), y_test)\n",
    "print('Test loss before training' , before_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (207996) != input nelement (103998)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-ed82c5b5c9b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Compute Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}: train loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2070\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (207996) != input nelement (103998)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch = 100\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred.squeeze(), y_train)\n",
    "   \n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(x_test)\n",
    "before_train = criterion(y_pred.squeeze(), y_test)\n",
    "print('Test loss before training' , before_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoilerPlate command\n",
    "It’s standard practice to start the notebook with the following three lines; they ensure that any edits to libraries you make are reloaded here automatically, and also that any charts or images displayed are shown in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A very simple MLP baseline\n",
    "* This is a very small dataset, so it's very easy to overfit. Tune carefully.\n",
    "* Check the \"Output\" tab for training logs.\n",
    "\"\"\"\n",
    "from subprocess import call\n",
    "import os\n",
    "\n",
    "FNULL = open(os.devnull, 'w')\n",
    "call(\"pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.0.3.zip\".split(\" \"), stdout=FNULL, stderr=FNULL)\n",
    "\n",
    "# set SEED\n",
    "os.environ[\"SEED\"] = \"42\"\n",
    "\n",
    "DEVICE =   torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "#     Dataset Utils\n",
    "# ======================\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def get_dataset(x, y):\n",
    "    return TensorDataset(\n",
    "        torch.from_numpy(x).float(),\n",
    "        torch.from_numpy(y).float()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataloader(x: np.array, y: np.array, batch_size: int, shuffle: bool = True, num_workers: int = 0):\n",
    "    dataset = get_dataset(x, y)\n",
    "    return DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ndarray(embedding_values):\n",
    "    results = []\n",
    "    for row in embedding_values:\n",
    "        arr = np.array(row)\n",
    "        results.append(\n",
    "            np.pad(arr, ((10 - arr.shape[0], 0), (0, 0)), 'constant')\n",
    "        )\n",
    "    # shape: (examples, emb_dim, seq_length)\n",
    "    return np.transpose(np.stack(results), (0, 2, 1))\n",
    "\n",
    "\n",
    "def read_dataset(data_dir=Path(\"data/\")):\n",
    "    if isinstance(data_dir, str):\n",
    "        data_dir = Path(data_dir)\n",
    "    df_train = pd.read_json(data_dir / 'train.json')\n",
    "    df_test = pd.read_json(data_dir / 'test.json')\n",
    "    x_train = get_ndarray(df_train.audio_embedding)\n",
    "    y_train = df_train.is_turkey.values\n",
    "    x_test = get_ndarray(df_test.audio_embedding)\n",
    "    test_id = df_test.vid_id\n",
    "    return x_train, y_train, x_test, test_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helperbot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5994739c0ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseBot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTriangularLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeightDecayOptimizerWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helperbot'"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "#     Model Creation, Training, and Inference\n",
    "# ==============================================\n",
    "import logging\n",
    "\n",
    "from helperbot.bot import BaseBot\n",
    "from helperbot.lr_scheduler import TriangularLR\n",
    "from helperbot.weight_decay import WeightDecayOptimizerWrapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TurkeyBot(BaseBot):\n",
    "    name = \"Turkey\"\n",
    "\n",
    "    def __init__(self, model, train_loader, val_loader, *, optimizer,\n",
    "                 avg_window=20, log_dir=\"./cache/logs/\",\n",
    "                 log_level=logging.INFO, checkpoint_dir=\"./cache/model_cache/\"):\n",
    "        super().__init__(\n",
    "            model, train_loader, val_loader,\n",
    "            optimizer=optimizer, avg_window=avg_window,\n",
    "            log_dir=log_dir, log_level=log_level, checkpoint_dir=checkpoint_dir,\n",
    "            batch_idx=0, echo=False, device=DEVICE\n",
    "        )\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.loss_format = \"%.8f\"\n",
    "\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, num_features, dropout=0.25, n_hid=128):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_features, n_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(n_hid),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(n_hid, n_hid // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(n_hid // 4),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hid // 4, 1),\n",
    "        )\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return self.model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    x_train, y_train, x_test, test_id = read_dataset(\"../input/\")\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "    test_loader = get_dataloader(\n",
    "        x_test, np.zeros(x_test.shape[0]), batch_size=128, shuffle=False)\n",
    "\n",
    "    test_pred_list, val_losses = [], []\n",
    "    kf = StratifiedKFold(n_splits=8, random_state=3829, shuffle=True)\n",
    "    for train_index, valid_index in kf.split(x_train, y_train):\n",
    "        train_loader = get_dataloader(\n",
    "            x_train[train_index], y_train[train_index],\n",
    "            batch_size=128, shuffle=True\n",
    "        )\n",
    "        val_loader = get_dataloader(\n",
    "            x_train[valid_index], y_train[valid_index],\n",
    "            batch_size=128, shuffle=False\n",
    "        )\n",
    "\n",
    "        model = MLPModel(128 * 10, dropout=0.25, n_hid=1024)\n",
    "        model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), betas=(0.9, 0.999), lr=1e-3, weight_decay=0)\n",
    "        optimizer = WeightDecayOptimizerWrapper(\n",
    "            optimizer, weight_decay=5e-3\n",
    "        )\n",
    "        batches_per_epoch = len(train_loader)\n",
    "        bot = TurkeyBot(\n",
    "            model, train_loader, val_loader,\n",
    "            optimizer=optimizer, avg_window=batches_per_epoch\n",
    "        )\n",
    "        n_steps = batches_per_epoch * 20\n",
    "        scheduler = TriangularLR(\n",
    "            optimizer, max_mul=8, ratio=8,\n",
    "            steps_per_cycle=n_steps\n",
    "        )\n",
    "        bot.train(\n",
    "            n_steps,\n",
    "            log_interval=batches_per_epoch // 2,\n",
    "            snapshot_interval=batches_per_epoch,\n",
    "            early_stopping_cnt=10, scheduler=scheduler)\n",
    "        val_preds = torch.sigmoid(bot.predict_avg(\n",
    "            val_loader, k=3, is_test=True).cpu()).numpy().clip(1e-5, 1-1e-5)\n",
    "        loss = log_loss(y_train[valid_index], val_preds)\n",
    "        print(\"AUC: %.6f\" % roc_auc_score(y_train[valid_index], val_preds))\n",
    "        print(\"Val loss: %.6f\" % loss)\n",
    "        if loss > 0.2:\n",
    "            print(\"Skipped...\")\n",
    "            # Ditch folds that perform terribly\n",
    "            bot.remove_checkpoints(keep=0)\n",
    "            continue\n",
    "        val_losses.append(loss)\n",
    "        test_pred_list.append(torch.sigmoid(bot.predict_avg(\n",
    "            test_loader, k=3, is_test=True).cpu()).numpy().clip(1e-5, 1-1e-5))\n",
    "        bot.remove_checkpoints(keep=0)\n",
    "\n",
    "    print(\"# of Folds used:\", len(val_losses))\n",
    "    val_loss = np.mean(val_losses)\n",
    "    test_preds = np.mean(test_pred_list, axis=0)\n",
    "    print(\"Validation losses: %.6f +- %.6f\" %\n",
    "          (np.mean(val_losses), np.std(val_losses)))\n",
    "\n",
    "    df_sub = pd.DataFrame({\n",
    "        \"vid_id\": test_id,\n",
    "        \"is_turkey\": test_preds\n",
    "    })\n",
    "    df_sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
